{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09609c17-2337-4956-aabd-9e8e69437021",
   "metadata": {},
   "source": [
    "# centerflow_extruded\n",
    "\n",
    "**centerflow_extruded** is a Python module for modeling glacier dynamics along flowlines raised to an extruded mesh, permitting higher-order modeling. It is mostly a direct analogue of the accompanying \"centerflow\" module. It provides tools with several core functionalities:\n",
    "\n",
    "1. **id finder**\n",
    "    Sometimes we need multiple IDs for a single glacier. It's useful to be able to discern the RGIv6 ID from the RGIv7 ID, for example.\n",
    "\n",
    "2. **Mesh generation**  \n",
    "   Construct a 1D finite element mesh along an RGI-defined glacier centerline, and extrude it to include a vertical coordinate, $\\zeta$, which ranges from 0 at the base to 1 at the surface.\n",
    "\n",
    "3. **Mesh trimming**\n",
    "    In case of partial DEMs or other data limitations.\n",
    "\n",
    "5. **Data interpolation**  \n",
    "   Interpolate gridded geospatial datasets (e.g., surface elevation, velocity, surface mass balance) onto the extruded mesh.\n",
    "\n",
    "6. **Function lifting**  \n",
    "   Reproject functions back to the extruded mesh after they have been flattened to the base mesh.\n",
    "\n",
    "7. **Smoothing**  \n",
    "   Smooth functions defined on an extruded mesh.\n",
    "\n",
    "8. **Bed inversion**  \n",
    "   Apply a forward-model-based bed inversion scheme following the approach of [van Pelt et al. (2013)](https://tc.copernicus.org/articles/7/987/2013/), using observed surface elevations to iteratively estimate basal topography.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48da0b-c3bf-4b26-9acd-4ea785dda8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import firedrake\n",
    "from firedrake.mesh import ExtrudedMeshTopology\n",
    "import geopandas as gpd\n",
    "import icepack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.io import MemoryFile\n",
    "import scipy.ndimage\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from shapely.geometry import LineString\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98f03e-b8e1-4f74-b0e4-271be9818aba",
   "metadata": {},
   "source": [
    "## rgi6_from_rgi7 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fa161-ee50-45c9-9906-978b00cbf4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgi6_from_rgi7(**kwargs):\n",
    "    rgiid = kwargs[\"rgiid\"]\n",
    "    rgi6_path = kwargs[\"rgi6_path\"]\n",
    "    rgi7_path = kwargs[\"rgi7_path\"]\n",
    "\n",
    "    # Load RGI7 outlines and get the matching geometry\n",
    "    gdf7 = gpd.read_file(rgi7_path)\n",
    "    outline = gdf7[gdf7['rgi_id'].str.contains(rgiid, regex=False)].geometry.values[0]\n",
    "\n",
    "    # Load RGI6 outlines and normalize ID column\n",
    "    gdf6 = gpd.read_file(rgi6_path)\n",
    "    if \"RGIId\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"RGIId\", \"geometry\"]].rename(columns={\"RGIId\": \"rgiid_6\"})\n",
    "    elif \"rgi_id\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"rgi_id\", \"geometry\"]].rename(columns={\"rgi_id\": \"rgiid_6\"})\n",
    "    else:\n",
    "        raise ValueError(f\"No RGI ID column found in {rgi6_path}\")\n",
    "\n",
    "    # Project to metric CRS for area calculation\n",
    "    target_crs = \"EPSG:32646\"\n",
    "    gdf6 = gdf6.to_crs(target_crs)\n",
    "    outline_gdf = gpd.GeoDataFrame(geometry=[outline], crs=gdf7.crs).to_crs(target_crs)\n",
    "\n",
    "    # Intersect and pick the largest overlap\n",
    "    inter = gpd.overlay(gdf6, outline_gdf, how=\"intersection\")\n",
    "    if inter.empty:\n",
    "        return None\n",
    "    inter[\"overlap_area_m2\"] = inter.geometry.area\n",
    "    best_match = inter.sort_values(\"overlap_area_m2\", ascending=False).iloc[0][\"rgiid_6\"]\n",
    "\n",
    "    # Keep only the \"15.xxxxx\" part\n",
    "    return best_match.split(\"-\", 1)[-1]\n",
    "\n",
    "\n",
    "def rgi7_from_rgi6(**kwargs):\n",
    "    rgiid = kwargs[\"rgiid\"]\n",
    "    rgi6_path = kwargs[\"rgi6_path\"]\n",
    "    rgi7_path = kwargs[\"rgi7_path\"]\n",
    "\n",
    "    # Load RGI6 outlines and get the matching geometry\n",
    "    gdf6 = gpd.read_file(rgi6_path)\n",
    "    if \"RGIId\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"RGIId\", \"geometry\"]].rename(columns={\"RGIId\": \"rgiid_6\"})\n",
    "    elif \"rgi_id\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"rgi_id\", \"geometry\"]].rename(columns={\"rgi_id\": \"rgiid_6\"})\n",
    "    else:\n",
    "        raise ValueError(f\"No RGI ID column found in {rgi6_path}\")\n",
    "    outline = gdf6[gdf6['rgiid_6'].str.contains(rgiid, regex=False)].geometry.values[0]\n",
    "\n",
    "    # Load RGI7 outlines\n",
    "    gdf7 = gpd.read_file(rgi7_path)[[\"rgi_id\", \"geometry\"]]\n",
    "\n",
    "    # Project to metric CRS for area calculation\n",
    "    target_crs = \"EPSG:32646\"\n",
    "    gdf7 = gdf7.to_crs(target_crs)\n",
    "    outline_gdf = gpd.GeoDataFrame(geometry=[outline], crs=gdf6.crs).to_crs(target_crs)\n",
    "\n",
    "    # Intersect and pick the largest overlap\n",
    "    inter = gpd.overlay(gdf7, outline_gdf, how=\"intersection\")\n",
    "    if inter.empty:\n",
    "        return None\n",
    "    inter[\"overlap_area_m2\"] = inter.geometry.area\n",
    "    best_match = inter.sort_values(\"overlap_area_m2\", ascending=False).iloc[0][\"rgi_id\"]\n",
    "\n",
    "    # Keep only the \"15-xxxxx\" part\n",
    "    return \"-\".join(best_match.split(\"-\")[3:])\n",
    "\n",
    "def latlon_from_rgi7(**kwargs):\n",
    "    rgiid_7   = kwargs[\"rgiid\"]\n",
    "    rgi7_path = kwargs[\"rgi7_path\"]\n",
    "\n",
    "    # Load and filter\n",
    "    gdf7 = gpd.read_file(rgi7_path)\n",
    "    match = gdf7[gdf7['rgi_id'].str.contains(rgiid_7, regex=False)]\n",
    "    if match.empty:\n",
    "        raise ValueError(f\"RGI7 ID '{rgiid_7}' not found in {rgi7_path}\")\n",
    "\n",
    "    # Reproject to a metric CRS for centroid calculation\n",
    "    metric_crs = \"EPSG:32646\"  # Bhutan region\n",
    "    centroid_metric = match.to_crs(metric_crs).geometry.centroid.iloc[0]\n",
    "\n",
    "    # Convert centroid back to geographic CRS\n",
    "    centroid_geo = gpd.GeoSeries([centroid_metric], crs=metric_crs).to_crs(\"EPSG:4326\").iloc[0]\n",
    "    lat, lon = centroid_geo.y, centroid_geo.x\n",
    "\n",
    "    # Build tile string\n",
    "    lat_prefix = \"N\" if lat >= 0 else \"S\"\n",
    "    lon_prefix = \"E\" if lon >= 0 else \"W\"\n",
    "    lat_deg = int(np.floor(np.abs(lat)))\n",
    "    lon_deg = int(np.floor(np.abs(lon)))\n",
    "    tile = f\"{lat_prefix}{lat_deg:02d}{lon_prefix}{lon_deg:03d}\"\n",
    "\n",
    "    return tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814be079-efe1-470b-9d7d-810eaa51d200",
   "metadata": {},
   "source": [
    "## centerline_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74911c-1902-4a36-8ac0-cd0bd1c7f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IntervalMeshResult:\n",
    "    mesh: firedrake.ExtrudedMesh\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "    X: np.ndarray\n",
    "    basal_coords: np.ndarray\n",
    "    surface_coords: np.ndarray\n",
    "    glacier_length: float\n",
    "    centerline: object\n",
    "    outline: object\n",
    "\n",
    "\n",
    "def centerline_mesh(**kwargs):\n",
    "    rgiid = kwargs.get('rgiid', '15-09534')\n",
    "    centerline_path = kwargs['centerline_path']\n",
    "    outline_path = kwargs['outline_path']\n",
    "    n_cells = kwargs['n_cells']\n",
    "\n",
    "    outlines = gpd.read_file(outline_path)\n",
    "    centerlines = gpd.read_file(centerline_path)\n",
    "    outline = outlines[outlines['rgi_id'].str.contains(rgiid)].geometry.values[0]\n",
    "    flowlines = centerlines[centerlines.intersects(outline)] #may contain severeral smaller tributary flowlines\n",
    "    centerline = flowlines.loc[flowlines.to_crs('EPSG:32646').length.idxmax(), 'geometry'] #so grab the longest one\n",
    "\n",
    "    geod = Geod(ellps = 'WGS84')\n",
    "    x, y = centerline.xy\n",
    "    distances = np.insert(np.cumsum([\n",
    "        geod.inv(x[i], y[i], x[i + 1], y[i + 1])[2]\n",
    "        for i in range(len(x) - 1)\n",
    "    ]), 0, 0)\n",
    "    glacier_length = distances[-1]\n",
    "\n",
    "    # Interpolate x, y to match n_cells + 1 vertices\n",
    "    uniform_dists = np.linspace(0, glacier_length, n_cells + 1)\n",
    "    x_interp = interp1d(distances, x)(uniform_dists)\n",
    "    y_interp = interp1d(distances, y)(uniform_dists)\n",
    "\n",
    "    base_mesh = firedrake.IntervalMesh(n_cells, glacier_length)\n",
    "    mesh = firedrake.ExtrudedMesh(base_mesh, layers = 1)\n",
    "    X = base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    Z_1 = np.ones_like(X)\n",
    "    Z_0 = np.zeros_like(X)\n",
    "    surface_coords = np.column_stack((X, Z_1))\n",
    "    basal_coords = np.column_stack((X, Z_0))\n",
    "\n",
    "    return IntervalMeshResult(\n",
    "        mesh = mesh,\n",
    "        x = np.array(x_interp),\n",
    "        y = np.array(y_interp),\n",
    "        X = X,\n",
    "        surface_coords = surface_coords,\n",
    "        basal_coords = basal_coords,\n",
    "        glacier_length = glacier_length,\n",
    "        centerline = centerline,\n",
    "        outline = outline\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b884d-3a02-4afb-8e5e-e2e5cd9ff19a",
   "metadata": {},
   "source": [
    "## crop_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d67a7-2d64-4185-833e-d4e884b6cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cut(line, d):\n",
    "    if d <= 0.0:\n",
    "        return [None, LineString(line.coords)]\n",
    "    if d >= line.length:\n",
    "        return [LineString(line.coords), None]\n",
    "    coords, acc = list(line.coords), 0.0\n",
    "    for i in range(len(coords) - 1):\n",
    "        p0, p1 = coords[i], coords[i + 1]\n",
    "        seg = LineString([p0, p1])\n",
    "        L = seg.length\n",
    "        if acc + L >= d:\n",
    "            t = (d - acc) / L\n",
    "            x = p0[0] + t * (p1[0] - p0[0])\n",
    "            y = p0[1] + t * (p1[1] - p0[1])\n",
    "            pt = (x, y)\n",
    "            return [LineString(coords[:i + 1] + [pt]), LineString([pt] + coords[i + 1:])]\n",
    "        acc += L\n",
    "    return [LineString(coords), None]\n",
    "\n",
    "def _segment(line, d0, d1):\n",
    "    left, mid = _cut(line, d0)\n",
    "    mid, right = _cut(mid, d1 - d0)\n",
    "    return mid\n",
    "\n",
    "def crop_mesh(**kwargs):\n",
    "    mesh = kwargs['mesh']\n",
    "    data_path = kwargs['data_path']\n",
    "\n",
    "    with rasterio.open(data_path) as src:\n",
    "        r_crs = src.crs\n",
    "        nodata = src.nodata\n",
    "\n",
    "    cl_m = gpd.GeoSeries([mesh.centerline], crs='EPSG:4326').to_crs(r_crs).iloc[0]\n",
    "\n",
    "    target_samples = 400\n",
    "    step = max(cl_m.length / target_samples, 25.0)\n",
    "    dists = np.arange(0.0, cl_m.length + step, step, dtype=float)\n",
    "    pts = [cl_m.interpolate(float(d)) for d in dists]\n",
    "\n",
    "    with rasterio.open(data_path) as src:\n",
    "        vals = np.array([v[0] for v in src.sample([(p.x, p.y) for p in pts])])\n",
    "\n",
    "    valid = ~np.isnan(vals) if nodata is None else (vals != nodata)\n",
    "    if not valid.any():\n",
    "        raise ValueError('No valid data found along centerline for the provided raster.')\n",
    "\n",
    "    first = int(np.argmax(valid))\n",
    "    last = int(len(valid) - 1 - np.argmax(valid[::-1]))\n",
    "\n",
    "    # If no cropping is needed, return unchanged mesh\n",
    "    if first == 0 and last == len(valid) - 1:\n",
    "        return mesh\n",
    "\n",
    "    d0, d1 = float(dists[first]), float(dists[last])\n",
    "    cl_m_cropped = _segment(cl_m, d0, d1)\n",
    "    cl_ll = gpd.GeoSeries([cl_m_cropped], crs=r_crs).to_crs('EPSG:4326').iloc[0]\n",
    "\n",
    "    geod = Geod(ellps='WGS84')\n",
    "    xs, ys = np.asarray(cl_ll.xy[0]), np.asarray(cl_ll.xy[1])\n",
    "    segs = [geod.inv(xs[i], ys[i], xs[i + 1], ys[i + 1])[2] for i in range(len(xs) - 1)]\n",
    "    new_len = float(np.sum(segs))\n",
    "\n",
    "    n_cells = len(mesh.X) - 1\n",
    "    base_mesh = firedrake.IntervalMesh(n_cells, new_len)\n",
    "    extruded = firedrake.ExtrudedMesh(base_mesh, layers=1)\n",
    "    X = base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    surface_coords = np.column_stack((X, np.ones_like(X)))\n",
    "    basal_coords = np.column_stack((X, np.zeros_like(X)))\n",
    "\n",
    "    return type(mesh)(\n",
    "        mesh = extruded,\n",
    "        x = xs,\n",
    "        y = ys,\n",
    "        X = X,\n",
    "        basal_coords = basal_coords,\n",
    "        surface_coords = surface_coords,\n",
    "        glacier_length = new_len,\n",
    "        centerline = cl_ll,\n",
    "        outline = mesh.outline,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f441d-e412-4ce4-90f0-bf6ea83fd14a",
   "metadata": {},
   "source": [
    "## map_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec1f50c-1bf9-4681-9edd-8c0617b3978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_mesh(**kwargs):\n",
    "    mesh = kwargs['mesh']\n",
    "    data_path = kwargs['data_path']\n",
    "    extension = Path(data_path).suffix.lower()\n",
    "    dimension = kwargs.get('dimension', 1)\n",
    "    element = kwargs.get('element', 'CG')\n",
    "    key_value = kwargs.get('key_value', 'n/a')\n",
    "    data_value = kwargs.get('data_value', 'n/a')\n",
    "    key_dataset = kwargs.get('key_dataset', None)\n",
    "    projection = kwargs.get('projection', 'EPSG:4326')\n",
    "\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "\n",
    "    if extension == '.tif':\n",
    "        x, y = mesh.x, mesh.y\n",
    "\n",
    "        with rasterio.open(data_path) as src:\n",
    "            src_crs = src.crs\n",
    "            target_crs = CRS.from_string(projection)\n",
    "\n",
    "            if src_crs != target_crs:\n",
    "                print(f'Reprojecting {data_path} from {src_crs} to {target_crs}')\n",
    "                transform, width, height = calculate_default_transform(\n",
    "                    src_crs, target_crs, src.width, src.height, *src.bounds)\n",
    "\n",
    "                meta = src.meta.copy()\n",
    "                meta.update({\n",
    "                    'crs': target_crs,\n",
    "                    'transform': transform,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "\n",
    "                with MemoryFile() as memfile:\n",
    "                    with memfile.open(**meta) as dst:\n",
    "                        for i in range(1, src.count + 1):\n",
    "                            reproject(\n",
    "                                source = rasterio.band(src, i),\n",
    "                                destination = rasterio.band(dst, i),\n",
    "                                src_transform = src.transform,\n",
    "                                src_crs = src_crs,\n",
    "                                dst_transform = transform,\n",
    "                                dst_crs = target_crs,\n",
    "                                resampling = Resampling.bilinear\n",
    "                            )\n",
    "                    with memfile.open() as reproj:\n",
    "                        values = np.array(list(reproj.sample(zip(x, y)))).flatten()\n",
    "            else:\n",
    "                values = np.array(list(src.sample(zip(x, y)))).flatten()\n",
    "\n",
    "        geod = Geod(ellps = 'WGS84')\n",
    "        distances = np.insert(np.cumsum([\n",
    "            geod.inv(x[i], y[i], x[i + 1], y[i + 1])[2] for i in range(len(x) - 1)\n",
    "        ]), 0, 0)\n",
    "\n",
    "        interp_func = interp1d(distances, values, bounds_error = False, fill_value = 'extrapolate')\n",
    "        interp_vals = interp_func(base_coords)\n",
    "\n",
    "    elif extension == '.csv':\n",
    "        df = pd.read_csv(data_path)\n",
    "        if key_value not in df.columns or data_value not in df.columns:\n",
    "            raise ValueError(f'CSV must include {key_value!r} and {data_value!r} columns.')\n",
    "        if key_dataset is None:\n",
    "            raise ValueError('Must provide \"key_dataset\" (a Firedrake Function) when using CSV input.')\n",
    "\n",
    "        key_array = key_dataset.dat.data_ro\n",
    "        interp_func = interp1d(df[key_value], df[data_value], bounds_error = False, fill_value = 'extrapolate')\n",
    "        interp_vals = interp_func(key_array)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported file extension: {extension}')\n",
    "\n",
    "    V = firedrake.FunctionSpace(mesh.mesh, element, dimension, vfamily = 'R', vdegree = 0)\n",
    "    data_function = firedrake.Function(V)\n",
    "    data_function.dat.data[:] = interp_vals\n",
    "\n",
    "    return data_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164ef62-c530-43a7-92c1-138ace2af59d",
   "metadata": {},
   "source": [
    "# lift_to_mesh\n",
    "\n",
    "This can be useful for function smoothing, as smoothing requires first flattening a function and then applying a gaussian filter. The resulting smooth function then needs to be reprojected to the extruded mesh. Possibly this may also be useful for other reasons too, but I haven't found any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c65c34-85a3-4b71-8b84-323c2f0fba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_to_mesh(**kwargs):\n",
    "    input_function = kwargs['function']\n",
    "    function_space = kwargs['function_space']\n",
    "    mesh = kwargs['mesh']\n",
    "\n",
    "    element = function_space.ufl_element()\n",
    "    horizontal_elem, vertical_elem = element.sub_elements\n",
    "    hfamily, vfamily = horizontal_elem.family(), vertical_elem.family()\n",
    "    hdegree, vdegree = horizontal_elem.degree(), vertical_elem.degree()\n",
    "\n",
    "    # Fast path: vertically uniform elements (e.g., CG2xR0)\n",
    "    if vfamily == 'R' and vdegree == 0:\n",
    "        f = firedrake.Function(function_space)\n",
    "        base_vals = input_function.dat.data_ro\n",
    "        f_data = f.dat.data\n",
    "\n",
    "        n_base = len(base_vals)\n",
    "        n_total = f_data.shape[0]\n",
    "        n_layers = n_total // n_base\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            f_data[layer::n_layers] = base_vals\n",
    "\n",
    "        return f\n",
    "\n",
    "    # Fallback: Interpolate base values at mesh coordinates\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    input_coords = np.linspace(0, mesh.glacier_length, len(input_function.dat.data_ro))\n",
    "    interp_func = interp1d(input_coords, input_function.dat.data_ro, bounds_error = False, fill_value = 'extrapolate')\n",
    "    interp_vals = interp_func(base_coords)\n",
    "\n",
    "    function_space_interp = firedrake.FunctionSpace(\n",
    "        mesh.mesh, hfamily, 1, vfamily = vfamily, vdegree = vdegree\n",
    "    )\n",
    "    f = firedrake.Function(function_space_interp)\n",
    "    f.dat.data[:] = interp_vals\n",
    "\n",
    "    function_space_proj = firedrake.FunctionSpace(\n",
    "        mesh.mesh, hfamily, hdegree, vfamily = vfamily, vdegree = vdegree\n",
    "    )\n",
    "    return firedrake.project(f, function_space_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4e10b-2bed-4d20-aeb1-5bd3be773165",
   "metadata": {},
   "source": [
    "# smooth_extruded_function\n",
    "\n",
    "Important for icepack's HO model, which can be somewhat finicky with convergence, especially when there's a lot of jitter in certain fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbba162-6465-49f4-8549-8159958fd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_extruded_function(**kwargs):\n",
    "    f = kwargs['function']\n",
    "    mesh = kwargs['mesh']\n",
    "    sigma = kwargs.get('sigma', None)\n",
    "    window_meters = kwargs.get('window', None)\n",
    "\n",
    "    f_flat = icepack.depth_average(f)\n",
    "    f_data = f_flat.dat.data_ro.copy()\n",
    "\n",
    "    # Compute dx (spacing in meters) from base mesh\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    dx = np.mean(np.diff(base_coords))\n",
    "\n",
    "    if sigma is None:\n",
    "        if window_meters is None:\n",
    "            raise ValueError('Must specify either \"sigma\" or \"window_meters\"')\n",
    "        sigma = window_meters / dx / 2.0  # Approximate: 2σ ≈ full width at half maximum\n",
    "\n",
    "    smoothed_data = scipy.ndimage.gaussian_filter1d(f_data, sigma = sigma)\n",
    "\n",
    "    f_flat_smoothed = f_flat.copy(deepcopy = True)\n",
    "    f_flat_smoothed.dat.data[:] = smoothed_data\n",
    "\n",
    "    f_smoothed = lift_to_mesh(\n",
    "        function = f_flat_smoothed,\n",
    "        mesh = mesh,\n",
    "        function_space = f.function_space()\n",
    "    )\n",
    "\n",
    "    return f_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccece1a2-0a56-44cd-bb8e-778b84c774d0",
   "metadata": {},
   "source": [
    "## solve_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f6e5d-0c77-4fbb-b051-03682a77b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InversionResult:\n",
    "    bed: firedrake.Function\n",
    "    misfits: list\n",
    "    bed_evolution: list\n",
    "    surface_evolution: list\n",
    "    thickness_evolution: list\n",
    "    velocity_evolution: list\n",
    "    s_ref: firedrake.Function\n",
    "\n",
    "\n",
    "def solve_bed(**kwargs):\n",
    "    # Inputs\n",
    "    mesh = kwargs['mesh']\n",
    "    s_init = kwargs['surface']\n",
    "    s_ref = kwargs.get('surface_2', s_init)       \n",
    "    H_guess = kwargs['thickness_guess']\n",
    "    u_guess = kwargs['velocity']\n",
    "    a = kwargs['accumulation']\n",
    "    A = kwargs['fluidity']\n",
    "    K = kwargs['K']\n",
    "    num_iterations = kwargs['num_iterations']\n",
    "    model = kwargs['model']\n",
    "    solver = kwargs['solver']\n",
    "    friction = kwargs['friction']\n",
    "\n",
    "    try: num_years = s_ref.year - s_init.year #extract the time diff from the DEMs, if applicable\n",
    "    except: num_years = kwargs['model_time'] #otherwise, need to choose how long to model for \n",
    "\n",
    "    try: Δt = round(list(a)[1] - list(a)[0], 10) #extract Δt from the SMB list, if applicable\n",
    "    except: Δt = kwargs['timestep'] #otherwise, it needs to be specified\n",
    "\n",
    "    # Function space and coordinates\n",
    "    Q = s_init.function_space()\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "\n",
    "    # Initial bed guess\n",
    "    bed_guess = firedrake.Function(Q).project(s_init - H_guess)\n",
    "\n",
    "    # Initialize storage\n",
    "    misfits = []\n",
    "    bed_evolution = [bed_guess.dat.data_ro.copy()]\n",
    "    surface_evolution = []\n",
    "    velocity_evolution = []\n",
    "    thickness_evolution = []\n",
    "\n",
    "    num_timesteps = int(num_years/Δt)\n",
    "\n",
    "    bed_correction = firedrake.Function(Q)\n",
    "    surface_misfit = firedrake.Function(Q)\n",
    "\n",
    "    for iteration in trange(num_iterations):\n",
    "        bed_mod = bed_guess.copy(deepcopy = True)\n",
    "        H_mod = firedrake.Function(Q).project(s_init - bed_mod)\n",
    "        H_0 = H_mod.copy(deepcopy = True)\n",
    "        u_mod = u_guess.copy(deepcopy = True)\n",
    "        s_mod = s_init.copy(deepcopy = True)\n",
    "\n",
    "        for step in range(num_timesteps):\n",
    "\n",
    "            try: accumulation = a[s_init.year + step*Δt] #if SMB is a dictionary with date keys\n",
    "            except: accumulation = a #otherwise\n",
    "\n",
    "            try:\n",
    "                u_mod = solver.diagnostic_solve(\n",
    "                    velocity = u_mod,\n",
    "                    thickness = H_mod,\n",
    "                    surface = s_mod,\n",
    "                    fluidity = A,\n",
    "                    friction = friction\n",
    "                )\n",
    "                \n",
    "                H_mod = solver.prognostic_solve(\n",
    "                    Δt,\n",
    "                    thickness = H_mod,\n",
    "                    velocity = u_mod,\n",
    "                    thickness_inflow = H_0,\n",
    "                    accumulation = accumulation,\n",
    "                )\n",
    "                s_mod.project(icepack.compute_surface(bed = bed_mod, thickness = H_mod))\n",
    "\n",
    "            except:\n",
    "                print(f'Bed solver failed on step {step + 1} of iteration {iteration + 1}')\n",
    "\n",
    "                return InversionResult(\n",
    "                    bed = bed_guess,\n",
    "                    misfits = misfits,\n",
    "                    bed_evolution = bed_evolution,\n",
    "                    surface_evolution = surface_evolution,\n",
    "                    velocity_evolution = velocity_evolution,\n",
    "                    thickness_evolution = thickness_evolution,\n",
    "                    s_ref = s_ref\n",
    "                )\n",
    "\n",
    "        surface_misfit.project(s_mod - s_ref)\n",
    "        bed_correction.project(-K * surface_misfit)\n",
    "        bed_guess.project(bed_mod + bed_correction)\n",
    "\n",
    "        # Store evolution values\n",
    "        misfits.append(float(firedrake.assemble(surface_misfit*firedrake.dx)/mesh.glacier_length))\n",
    "        # misfits.append(np.linalg.norm(surface_misfit.dat.data_ro))\n",
    "        bed_evolution.append(bed_guess.dat.data_ro.copy())\n",
    "        surface_evolution.append(s_mod.dat.data_ro.copy())\n",
    "        thickness_evolution.append(H_mod.dat.data_ro.copy())\n",
    "        velocity_lifted = lift_to_mesh(\n",
    "            function = icepack.depth_average(u_mod),\n",
    "            mesh = mesh,\n",
    "            function_space = s_mod.function_space()\n",
    "        )\n",
    "        velocity_evolution.append(velocity_lifted.dat.data_ro.copy())\n",
    "\n",
    "    return InversionResult(\n",
    "        bed = bed_guess,\n",
    "        misfits = misfits,\n",
    "        bed_evolution = bed_evolution,\n",
    "        surface_evolution = surface_evolution,\n",
    "        velocity_evolution = velocity_evolution,\n",
    "        thickness_evolution = thickness_evolution,\n",
    "        s_ref = s_ref\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63f4cd-59e7-437c-b94e-2ac269cea457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script centerflow_extruded.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev2025)",
   "language": "python",
   "name": "dev2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
