{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57de57d-b4b5-41a7-8b97-ce05bb2e9b76",
   "metadata": {},
   "source": [
    "# centerflow_extruded\n",
    "\n",
    "**centerflow_extruded** is a Python module for modeling glacier dynamics along flowlines raised to an extruded mesh, permitting higher-order modeling. It provides tools with five core functionalities:\n",
    "\n",
    "1. **Mesh generation**  \n",
    "   Construct a 1D finite element mesh along an RGI-defined glacier centerline, and extrude it to include a vertical coordinate, $\\zeta$, which ranges from 0 at the base to 1 at the surface.\n",
    "\n",
    "2. **Data interpolation**  \n",
    "   Interpolate gridded geospatial datasets (e.g., surface elevation, velocity, surface mass balance) onto the extruded mesh.\n",
    "\n",
    "3. **Function lifting**  \n",
    "   Reproject functions back to the extruded mesh after they have been flattened to the base mesh.\n",
    "\n",
    "4. **Smoothing**  \n",
    "   Smooth functions defined on an extruded mesh.\n",
    "\n",
    "5. **Bed inversion**  \n",
    "   Apply a forward-model-based bed inversion scheme following the approach of [van Pelt et al. (2013)](https://tc.copernicus.org/articles/7/987/2013/), using observed surface elevations to iteratively estimate basal topography.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2319b02-b840-4848-96fc-6f3e57e3996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import firedrake\n",
    "from firedrake.mesh import ExtrudedMeshTopology\n",
    "import geopandas as gpd\n",
    "import icepack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.io import MemoryFile\n",
    "import scipy.ndimage\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee8f8b-88b8-4c94-9ded-62d0cf3bdf74",
   "metadata": {},
   "source": [
    "## centerline_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248783f-fb05-4f84-ac9b-8d51c6f2c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IntervalMeshResult:\n",
    "    mesh: firedrake.ExtrudedMesh\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "    glacier_length: float\n",
    "\n",
    "\n",
    "def centerline_mesh(**kwargs):\n",
    "    rgiid = kwargs.get('rgiid', '15-09534')\n",
    "    centerline_path = kwargs['centerline_path']\n",
    "    outline_path = kwargs['outline_path']\n",
    "    n_cells = kwargs['n_cells']\n",
    "\n",
    "    outlines = gpd.read_file(outline_path)\n",
    "    centerlines = gpd.read_file(centerline_path)\n",
    "    outline = outlines[outlines['rgi_id'].str.contains(rgiid)].geometry.values[0]\n",
    "    centerline = centerlines[centerlines.intersects(outline)].geometry.values[0]\n",
    "\n",
    "    geod = Geod(ellps = 'WGS84')\n",
    "    x, y = centerline.xy\n",
    "    distances = np.insert(np.cumsum([\n",
    "        geod.inv(x[i], y[i], x[i + 1], y[i + 1])[2]\n",
    "        for i in range(len(x) - 1)\n",
    "    ]), 0, 0)\n",
    "    glacier_length = distances[-1]\n",
    "\n",
    "    # Interpolate x, y to match n_cells + 1 vertices\n",
    "    uniform_dists = np.linspace(0, glacier_length, n_cells + 1)\n",
    "    x_interp = interp1d(distances, x)(uniform_dists)\n",
    "    y_interp = interp1d(distances, y)(uniform_dists)\n",
    "\n",
    "    base_mesh = firedrake.IntervalMesh(n_cells, glacier_length)\n",
    "    mesh = firedrake.ExtrudedMesh(base_mesh, layers = 1)\n",
    "\n",
    "    return IntervalMeshResult(\n",
    "        mesh = mesh,\n",
    "        x = np.array(x_interp),\n",
    "        y = np.array(y_interp),\n",
    "        glacier_length = glacier_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbeb080-5ad1-4ffb-930b-46dc97ec7519",
   "metadata": {},
   "source": [
    "## map_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77aa40-38c8-4d73-b6cc-9a434b98c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_mesh(**kwargs):\n",
    "    mesh = kwargs['mesh']\n",
    "    data_path = kwargs['data_path']\n",
    "    extension = Path(data_path).suffix.lower()\n",
    "    dimension = kwargs.get('dimension', 1)\n",
    "    element = kwargs.get('element', 'CG')\n",
    "    key_value = kwargs.get('key_value', 'n/a')\n",
    "    data_value = kwargs.get('data_value', 'n/a')\n",
    "    key_dataset = kwargs.get('key_dataset', None)\n",
    "    projection = kwargs.get('projection', 'EPSG:4326')\n",
    "\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "\n",
    "    if extension == '.tif':\n",
    "        x, y = mesh.x, mesh.y\n",
    "\n",
    "        with rasterio.open(data_path) as src:\n",
    "            src_crs = src.crs\n",
    "            target_crs = CRS.from_string(projection)\n",
    "\n",
    "            if src_crs != target_crs:\n",
    "                print(f'Reprojecting {data_path} from {src_crs} to {target_crs}')\n",
    "                transform, width, height = calculate_default_transform(\n",
    "                    src_crs, target_crs, src.width, src.height, *src.bounds)\n",
    "\n",
    "                meta = src.meta.copy()\n",
    "                meta.update({\n",
    "                    'crs': target_crs,\n",
    "                    'transform': transform,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "\n",
    "                with MemoryFile() as memfile:\n",
    "                    with memfile.open(**meta) as dst:\n",
    "                        for i in range(1, src.count + 1):\n",
    "                            reproject(\n",
    "                                source = rasterio.band(src, i),\n",
    "                                destination = rasterio.band(dst, i),\n",
    "                                src_transform = src.transform,\n",
    "                                src_crs = src_crs,\n",
    "                                dst_transform = transform,\n",
    "                                dst_crs = target_crs,\n",
    "                                resampling = Resampling.bilinear\n",
    "                            )\n",
    "                    with memfile.open() as reproj:\n",
    "                        values = np.array(list(reproj.sample(zip(x, y)))).flatten()\n",
    "            else:\n",
    "                values = np.array(list(src.sample(zip(x, y)))).flatten()\n",
    "\n",
    "        geod = Geod(ellps = 'WGS84')\n",
    "        distances = np.insert(np.cumsum([\n",
    "            geod.inv(x[i], y[i], x[i + 1], y[i + 1])[2] for i in range(len(x) - 1)\n",
    "        ]), 0, 0)\n",
    "\n",
    "        interp_func = interp1d(distances, values, bounds_error = False, fill_value = 'extrapolate')\n",
    "        interp_vals = interp_func(base_coords)\n",
    "\n",
    "    elif extension == '.csv':\n",
    "        df = pd.read_csv(data_path)\n",
    "        if key_value not in df.columns or data_value not in df.columns:\n",
    "            raise ValueError(f'CSV must include {key_value!r} and {data_value!r} columns.')\n",
    "        if key_dataset is None:\n",
    "            raise ValueError('Must provide \"key_dataset\" (a Firedrake Function) when using CSV input.')\n",
    "\n",
    "        key_array = key_dataset.dat.data_ro\n",
    "        interp_func = interp1d(df[key_value], df[data_value], bounds_error = False, fill_value = 'extrapolate')\n",
    "        interp_vals = interp_func(key_array)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported file extension: {extension}')\n",
    "\n",
    "    V = firedrake.FunctionSpace(mesh.mesh, element, dimension, vfamily = 'R', vdegree = 0)\n",
    "    data_function = firedrake.Function(V)\n",
    "    data_function.dat.data[:] = interp_vals\n",
    "\n",
    "    return data_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7e80e-ce24-42cc-90fe-cab0828e9157",
   "metadata": {},
   "source": [
    "# lift_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad83bd-18b9-453b-8d56-5125d4e5255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_to_mesh(**kwargs):\n",
    "    input_function = kwargs['function']\n",
    "    function_space = kwargs['function_space']\n",
    "    mesh = kwargs['mesh']\n",
    "\n",
    "    element = function_space.ufl_element()\n",
    "    horizontal_elem, vertical_elem = element.sub_elements\n",
    "    hfamily, vfamily = horizontal_elem.family(), vertical_elem.family()\n",
    "    hdegree, vdegree = horizontal_elem.degree(), vertical_elem.degree()\n",
    "\n",
    "    # Fast path: vertically uniform elements (e.g., CG2xR0)\n",
    "    if vfamily == 'R' and vdegree == 0:\n",
    "        f = firedrake.Function(function_space)\n",
    "        base_vals = input_function.dat.data_ro\n",
    "        f_data = f.dat.data\n",
    "\n",
    "        n_base = len(base_vals)\n",
    "        n_total = f_data.shape[0]\n",
    "        n_layers = n_total // n_base\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            f_data[layer::n_layers] = base_vals\n",
    "\n",
    "        return f\n",
    "\n",
    "    # Fallback: Interpolate base values at mesh coordinates\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    input_coords = np.linspace(0, mesh.glacier_length, len(input_function.dat.data_ro))\n",
    "    interp_func = interp1d(input_coords, input_function.dat.data_ro, bounds_error = False, fill_value = 'extrapolate')\n",
    "    interp_vals = interp_func(base_coords)\n",
    "\n",
    "    function_space_interp = firedrake.FunctionSpace(\n",
    "        mesh.mesh, hfamily, 1, vfamily = vfamily, vdegree = vdegree\n",
    "    )\n",
    "    f = firedrake.Function(function_space_interp)\n",
    "    f.dat.data[:] = interp_vals\n",
    "\n",
    "    function_space_proj = firedrake.FunctionSpace(\n",
    "        mesh.mesh, hfamily, hdegree, vfamily = vfamily, vdegree = vdegree\n",
    "    )\n",
    "    return firedrake.project(f, function_space_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e1636-6800-4405-bb97-8af26fecc940",
   "metadata": {},
   "source": [
    "# smooth_extruded_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624db6d5-e6c6-4b90-906b-ac44c6b3b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_extruded_function(**kwargs):\n",
    "    f = kwargs['function']\n",
    "    mesh = kwargs['mesh']\n",
    "    sigma = kwargs.get('sigma', None)\n",
    "    window_meters = kwargs.get('window', None)\n",
    "\n",
    "    f_flat = icepack.depth_average(f)\n",
    "    f_data = f_flat.dat.data_ro.copy()\n",
    "\n",
    "    # Compute dx (spacing in meters) from base mesh\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    dx = np.mean(np.diff(base_coords))\n",
    "\n",
    "    if sigma is None:\n",
    "        if window_meters is None:\n",
    "            raise ValueError('Must specify either \"sigma\" or \"window_meters\"')\n",
    "        sigma = window_meters / dx / 2.0  # Approximate: 2σ ≈ full width at half maximum\n",
    "\n",
    "    smoothed_data = scipy.ndimage.gaussian_filter1d(f_data, sigma = sigma)\n",
    "\n",
    "    f_flat_smoothed = f_flat.copy(deepcopy = True)\n",
    "    f_flat_smoothed.dat.data[:] = smoothed_data\n",
    "\n",
    "    f_smoothed = lift_to_mesh(\n",
    "        function = f_flat_smoothed,\n",
    "        mesh = mesh,\n",
    "        function_space = f.function_space()\n",
    "    )\n",
    "\n",
    "    return f_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c464ff-e7d4-49a0-86c2-16a1b243a163",
   "metadata": {},
   "source": [
    "## solve_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d6c84-6cde-44e3-b6a8-150e2df73d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InversionResult:\n",
    "    bed: firedrake.Function\n",
    "    misfits: list\n",
    "    bed_evolution: list\n",
    "    surface_evolution: list\n",
    "    thickness_evolution: list\n",
    "    velocity_evolution: list\n",
    "\n",
    "\n",
    "def solve_bed(**kwargs):\n",
    "    # Inputs\n",
    "    mesh = kwargs['mesh']\n",
    "    s_ref = kwargs['surface']\n",
    "    H_guess = kwargs['thickness_guess']\n",
    "    u_guess = kwargs['velocity']\n",
    "    a = kwargs['accumulation']\n",
    "    A = kwargs['fluidity']\n",
    "    K = kwargs['K']\n",
    "    Δt = kwargs['timestep']\n",
    "    num_years = kwargs['model_time']\n",
    "    num_iterations = kwargs['num_iterations']\n",
    "    model = kwargs['model']\n",
    "    solver = kwargs['solver']\n",
    "    friction = kwargs['friction']\n",
    "    window = kwargs.get('smoothing_window', None)\n",
    "    sigma = kwargs.get('sigma', None)\n",
    "\n",
    "    # Function space and coordinates\n",
    "    Q = s_ref.function_space()\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "\n",
    "    # Initial bed guess\n",
    "    bed_guess = firedrake.Function(Q).project(s_ref - H_guess)\n",
    "\n",
    "    # Initialize storage\n",
    "    misfits = []\n",
    "    bed_evolution = [bed_guess.dat.data_ro.copy()]\n",
    "    surface_evolution = []\n",
    "    velocity_evolution = []\n",
    "    thickness_evolution = []\n",
    "\n",
    "    num_timesteps = int(num_years / Δt)\n",
    "\n",
    "    bed_correction = firedrake.Function(Q)\n",
    "    surface_misfit = firedrake.Function(Q)\n",
    "\n",
    "    for iteration in trange(num_iterations):\n",
    "        bed_mod = bed_guess.copy(deepcopy = True)\n",
    "        H_mod = firedrake.Function(Q).project(s_ref - bed_mod)\n",
    "        u_mod = u_guess.copy(deepcopy = True)\n",
    "        s_mod = s_ref.copy(deepcopy = True)\n",
    "\n",
    "        for step in range(num_timesteps):\n",
    "            u_mod = solver.diagnostic_solve(\n",
    "                velocity = u_mod,\n",
    "                thickness = H_mod,\n",
    "                surface = s_mod,\n",
    "                fluidity = A,\n",
    "                friction = friction\n",
    "            )\n",
    "            H_mod = solver.prognostic_solve(\n",
    "                Δt,\n",
    "                thickness = H_mod,\n",
    "                velocity = u_mod,\n",
    "                thickness_inflow = H_mod,\n",
    "                accumulation = a,\n",
    "            )\n",
    "            s_mod.project(icepack.compute_surface(bed = bed_mod, thickness = H_mod))\n",
    "            # s_mod.project(bed_mod + H_mod)\n",
    "\n",
    "        surface_misfit.project(s_mod - s_ref)\n",
    "        bed_correction.project(-K * surface_misfit)\n",
    "        bed_guess.project(bed_mod + bed_correction)\n",
    "\n",
    "        if window is not None or sigma is not None:\n",
    "            bed_guess = smooth_extruded_function(\n",
    "                function = bed_guess,\n",
    "                mesh = mesh,\n",
    "                window = window,\n",
    "                sigma = sigma\n",
    "            )\n",
    "\n",
    "        # Store evolution values\n",
    "        misfits.append(np.linalg.norm(surface_misfit.dat.data_ro))\n",
    "        bed_evolution.append(bed_guess.dat.data_ro.copy())\n",
    "        surface_evolution.append(s_mod.dat.data_ro.copy())\n",
    "        thickness_evolution.append(H_mod.dat.data_ro.copy())\n",
    "        velocity_lifted = lift_to_mesh(\n",
    "            function = icepack.depth_average(u_mod),\n",
    "            mesh = mesh,\n",
    "            function_space = s_mod.function_space()\n",
    "        )\n",
    "        velocity_evolution.append(velocity_lifted.dat.data_ro.copy())\n",
    "\n",
    "    return InversionResult(\n",
    "        bed = bed_guess,\n",
    "        misfits = misfits,\n",
    "        bed_evolution = bed_evolution,\n",
    "        surface_evolution = surface_evolution,\n",
    "        velocity_evolution = velocity_evolution,\n",
    "        thickness_evolution = thickness_evolution\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268e3ac-a930-43d6-b20b-0356438213fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script centerflow_extruded.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev2025)",
   "language": "python",
   "name": "dev2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
