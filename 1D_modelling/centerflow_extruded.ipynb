{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09609c17-2337-4956-aabd-9e8e69437021",
   "metadata": {},
   "source": [
    "# centerflow_extruded\n",
    "\n",
    "**centerflow_extruded** is a Python module for modeling glacier dynamics along flowlines raised to an extruded mesh, permitting higher-order modeling. It is mostly a direct analogue of the accompanying \"centerflow\" module. It provides tools with several core functionalities:\n",
    "\n",
    "1. **ID finder**\n",
    "    Sometimes we need multiple IDs for a single glacier. It's useful to be able to discern the RGIv6 ID from the RGIv7 ID, for example.\n",
    "\n",
    "2. **Mesh generation**  \n",
    "   Construct a 1D finite element mesh along an RGI-defined glacier centerline, and extrude it to include a vertical coordinate, $\\zeta$, which ranges from 0 at the base to 1 at the surface.\n",
    "\n",
    "5. **Mesh trimming**  \n",
    "   In case of partial DEMs or whatever. \n",
    "\n",
    "5. **Data interpolation**  \n",
    "   Interpolate gridded geospatial datasets (e.g., surface elevation, velocity, surface mass balance) onto the extruded mesh.\n",
    "\n",
    "6. **Function lifting**  \n",
    "   Reproject functions back to the extruded mesh after they have been flattened to the base mesh.\n",
    "\n",
    "7. **Smoothing**  \n",
    "   Smooth functions defined on an extruded mesh.\n",
    "\n",
    "8. **Bed inversion**  \n",
    "   Apply a forward-model-based bed inversion scheme following the approach of [van Pelt et al. (2013)](https://tc.copernicus.org/articles/7/987/2013/), using observed surface elevations to iteratively estimate basal topography.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48da0b-c3bf-4b26-9acd-4ea785dda8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import firedrake\n",
    "from firedrake.mesh import ExtrudedMeshTopology\n",
    "import geopandas as gpd\n",
    "import icepack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.io import MemoryFile\n",
    "import scipy.ndimage\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from shapely.geometry import LineString\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98f03e-b8e1-4f74-b0e4-271be9818aba",
   "metadata": {},
   "source": [
    "## rgi6_from_rgi7 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fa161-ee50-45c9-9906-978b00cbf4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgi6_from_rgi7(**kwargs):\n",
    "    rgiid = kwargs[\"rgiid\"]\n",
    "    rgi6_path = kwargs[\"rgi6_path\"]\n",
    "    rgi7_path = kwargs[\"rgi7_path\"]\n",
    "\n",
    "    # Load RGI7 outlines and get the matching geometry\n",
    "    gdf7 = gpd.read_file(rgi7_path)\n",
    "    outline = gdf7[gdf7['rgi_id'].str.contains(rgiid, regex=False)].geometry.values[0]\n",
    "\n",
    "    # Load RGI6 outlines and normalize ID column\n",
    "    gdf6 = gpd.read_file(rgi6_path)\n",
    "    if \"RGIId\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"RGIId\", \"geometry\"]].rename(columns={\"RGIId\": \"rgiid_6\"})\n",
    "    elif \"rgi_id\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"rgi_id\", \"geometry\"]].rename(columns={\"rgi_id\": \"rgiid_6\"})\n",
    "    else:\n",
    "        raise ValueError(f\"No RGI ID column found in {rgi6_path}\")\n",
    "\n",
    "    # Project to metric CRS for area calculation\n",
    "    target_crs = \"EPSG:32646\"\n",
    "    gdf6 = gdf6.to_crs(target_crs)\n",
    "    outline_gdf = gpd.GeoDataFrame(geometry=[outline], crs=gdf7.crs).to_crs(target_crs)\n",
    "\n",
    "    # Intersect and pick the largest overlap\n",
    "    inter = gpd.overlay(gdf6, outline_gdf, how=\"intersection\")\n",
    "    if inter.empty:\n",
    "        return None\n",
    "    inter[\"overlap_area_m2\"] = inter.geometry.area\n",
    "    best_match = inter.sort_values(\"overlap_area_m2\", ascending=False).iloc[0][\"rgiid_6\"]\n",
    "\n",
    "    # Keep only the \"15.xxxxx\" part\n",
    "    return best_match.split(\"-\", 1)[-1]\n",
    "\n",
    "\n",
    "def rgi7_from_rgi6(**kwargs):\n",
    "    rgiid = kwargs[\"rgiid\"]\n",
    "    rgi6_path = kwargs[\"rgi6_path\"]\n",
    "    rgi7_path = kwargs[\"rgi7_path\"]\n",
    "\n",
    "    # Load RGI6 outlines and get the matching geometry\n",
    "    gdf6 = gpd.read_file(rgi6_path)\n",
    "    if \"RGIId\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"RGIId\", \"geometry\"]].rename(columns={\"RGIId\": \"rgiid_6\"})\n",
    "    elif \"rgi_id\" in gdf6.columns:\n",
    "        gdf6 = gdf6[[\"rgi_id\", \"geometry\"]].rename(columns={\"rgi_id\": \"rgiid_6\"})\n",
    "    else:\n",
    "        raise ValueError(f\"No RGI ID column found in {rgi6_path}\")\n",
    "    outline = gdf6[gdf6['rgiid_6'].str.contains(rgiid, regex=False)].geometry.values[0]\n",
    "\n",
    "    # Load RGI7 outlines\n",
    "    gdf7 = gpd.read_file(rgi7_path)[[\"rgi_id\", \"geometry\"]]\n",
    "\n",
    "    # Project to metric CRS for area calculation\n",
    "    target_crs = \"EPSG:32646\"\n",
    "    gdf7 = gdf7.to_crs(target_crs)\n",
    "    outline_gdf = gpd.GeoDataFrame(geometry=[outline], crs=gdf6.crs).to_crs(target_crs)\n",
    "\n",
    "    # Intersect and pick the largest overlap\n",
    "    inter = gpd.overlay(gdf7, outline_gdf, how=\"intersection\")\n",
    "    if inter.empty:\n",
    "        return None\n",
    "    inter[\"overlap_area_m2\"] = inter.geometry.area\n",
    "    best_match = inter.sort_values(\"overlap_area_m2\", ascending=False).iloc[0][\"rgi_id\"]\n",
    "\n",
    "    # Keep only the \"15-xxxxx\" part\n",
    "    return \"-\".join(best_match.split(\"-\")[3:])\n",
    "\n",
    "def latlon_from_rgi7(**kwargs):\n",
    "    rgiid_7   = kwargs[\"rgiid\"]\n",
    "    rgi7_path = kwargs[\"rgi7_path\"]\n",
    "\n",
    "    # Load and filter\n",
    "    gdf7 = gpd.read_file(rgi7_path)\n",
    "    match = gdf7[gdf7['rgi_id'].str.contains(rgiid_7, regex=False)]\n",
    "    if match.empty:\n",
    "        raise ValueError(f\"RGI7 ID '{rgiid_7}' not found in {rgi7_path}\")\n",
    "\n",
    "    # Reproject to a metric CRS for centroid calculation\n",
    "    metric_crs = \"EPSG:32646\"  # Bhutan region\n",
    "    centroid_metric = match.to_crs(metric_crs).geometry.centroid.iloc[0]\n",
    "\n",
    "    # Convert centroid back to geographic CRS\n",
    "    centroid_geo = gpd.GeoSeries([centroid_metric], crs=metric_crs).to_crs(\"EPSG:4326\").iloc[0]\n",
    "    lat, lon = centroid_geo.y, centroid_geo.x\n",
    "\n",
    "    # Build tile string\n",
    "    lat_prefix = \"N\" if lat >= 0 else \"S\"\n",
    "    lon_prefix = \"E\" if lon >= 0 else \"W\"\n",
    "    lat_deg = int(np.floor(np.abs(lat)))\n",
    "    lon_deg = int(np.floor(np.abs(lon)))\n",
    "    tile = f\"{lat_prefix}{lat_deg:02d}{lon_prefix}{lon_deg:03d}\"\n",
    "\n",
    "    return tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814be079-efe1-470b-9d7d-810eaa51d200",
   "metadata": {},
   "source": [
    "## centerline_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74911c-1902-4a36-8ac0-cd0bd1c7f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IntervalMeshResult:\n",
    "    mesh: firedrake.ExtrudedMesh      # extruded in HO case\n",
    "    x: np.ndarray                     # lon along centerline (possibly extended/truncated)\n",
    "    y: np.ndarray                     # lat along centerline\n",
    "    X: np.ndarray                     # base-mesh chainage coordinates (m)\n",
    "    basal_coords: np.ndarray          # (X, 0)\n",
    "    surface_coords: np.ndarray        # (X, 1)\n",
    "    length: float                     # domain length (m)\n",
    "    centerline: object                # shapely LineString\n",
    "    outline: object                   # glacier outline geometry\n",
    "\n",
    "def centerline_mesh(**kwargs):\n",
    "    rgiid = kwargs.get('rgiid', '15-09534')\n",
    "    centerline_path = kwargs.get('centerline_path', None)\n",
    "    outline_path = kwargs.get('outline_path', None)\n",
    "    extra_length = float(kwargs.get('extra_length', 0.0))  # may be + (extend) or â€“ (truncate)\n",
    "    n_cells = int(kwargs['n_cells'])\n",
    "    prev = kwargs.get('mesh', None)  # optionally reuse outline/centerline from an existing mesh\n",
    "\n",
    "    # Get outline + centerline in lon/lat\n",
    "    if prev is None:\n",
    "        if centerline_path is None or outline_path is None:\n",
    "            raise ValueError(\"Provide centerline_path and outline_path (or pass mesh=...).\")\n",
    "        outlines = gpd.read_file(outline_path)\n",
    "        centerlines = gpd.read_file(centerline_path)\n",
    "        outline = outlines[outlines['rgi_id'].str.contains(rgiid)].geometry.values[0]\n",
    "        flowlines = centerlines[centerlines.intersects(outline)]\n",
    "        centerline = flowlines.loc[flowlines.to_crs('EPSG:32646').length.idxmax(), 'geometry']\n",
    "    else:\n",
    "        outline = prev.outline\n",
    "        centerline = prev.centerline\n",
    "\n",
    "    # Extract and prepare arrays\n",
    "    geod = Geod(ellps='WGS84')\n",
    "    x_ll, y_ll = centerline.xy\n",
    "    x_ll = np.asarray(x_ll, dtype=float)\n",
    "    y_ll = np.asarray(y_ll, dtype=float)\n",
    "\n",
    "    # Cumulative geodesic chainage along original line\n",
    "    seg = np.array([geod.inv(x_ll[i], y_ll[i], x_ll[i+1], y_ll[i+1])[2] for i in range(len(x_ll) - 1)], dtype=float)\n",
    "    chainage = np.concatenate(([0.0], np.cumsum(seg)))\n",
    "    base_len = float(chainage[-1])\n",
    "    new_len = base_len + extra_length\n",
    "    if new_len <= 0.0:\n",
    "        raise ValueError(\"Resulting length must be > 0.\")\n",
    "\n",
    "    # Extend or truncate geometry to match new_len\n",
    "    if extra_length > 0.0:\n",
    "        az, _, _ = geod.inv(x_ll[-2], y_ll[-2], x_ll[-1], y_ll[-1])\n",
    "        x_new, y_new, _ = geod.fwd(x_ll[-1], y_ll[-1], az, extra_length)\n",
    "        x_mod = np.append(x_ll, x_new)\n",
    "        y_mod = np.append(y_ll, y_new)\n",
    "    elif extra_length < 0.0:\n",
    "        idx = int(np.searchsorted(chainage, new_len, side='right') - 1)\n",
    "        rem = new_len - chainage[idx]\n",
    "        if rem == 0.0:\n",
    "            x_mod = x_ll[:idx+1]\n",
    "            y_mod = y_ll[:idx+1]\n",
    "        else:\n",
    "            az, _, _ = geod.inv(x_ll[idx], y_ll[idx], x_ll[idx+1], y_ll[idx+1])\n",
    "            x_cut, y_cut, _ = geod.fwd(x_ll[idx], y_ll[idx], az, rem)\n",
    "            x_mod = np.r_[x_ll[:idx+1], x_cut]\n",
    "            y_mod = np.r_[y_ll[:idx+1], y_cut]\n",
    "    else:\n",
    "        x_mod, y_mod = x_ll, y_ll\n",
    "\n",
    "    centerline = LineString(np.column_stack((x_mod, y_mod)))\n",
    "\n",
    "    # Build meshes over [0, new_len]\n",
    "    base_mesh = firedrake.IntervalMesh(n_cells, new_len)\n",
    "    mesh = firedrake.ExtrudedMesh(base_mesh, layers=1)\n",
    "\n",
    "    X = base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    basal_coords = np.column_stack((X, np.zeros_like(X)))\n",
    "    surface_coords = np.column_stack((X, np.ones_like(X)))\n",
    "\n",
    "    return IntervalMeshResult(\n",
    "        mesh=mesh,\n",
    "        x=x_mod,\n",
    "        y=y_mod,\n",
    "        X=X,\n",
    "        basal_coords=basal_coords,\n",
    "        surface_coords=surface_coords,\n",
    "        length=new_len,\n",
    "        centerline=centerline,\n",
    "        outline=outline,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b884d-3a02-4afb-8e5e-e2e5cd9ff19a",
   "metadata": {},
   "source": [
    "## crop_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d67a7-2d64-4185-833e-d4e884b6cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cut(line, d):\n",
    "    if d <= 0.0:\n",
    "        return [None, LineString(line.coords)]\n",
    "    if d >= line.length:\n",
    "        return [LineString(line.coords), None]\n",
    "    coords, acc = list(line.coords), 0.0\n",
    "    for i in range(len(coords) - 1):\n",
    "        p0, p1 = coords[i], coords[i + 1]\n",
    "        seg = LineString([p0, p1])\n",
    "        L = seg.length\n",
    "        if acc + L >= d:\n",
    "            t = (d - acc) / L\n",
    "            x = p0[0] + t * (p1[0] - p0[0])\n",
    "            y = p0[1] + t * (p1[1] - p0[1])\n",
    "            pt = (x, y)\n",
    "            return [LineString(coords[:i + 1] + [pt]), LineString([pt] + coords[i + 1:])]\n",
    "        acc += L\n",
    "    return [LineString(coords), None]\n",
    "\n",
    "def _segment(line, d0, d1):\n",
    "    left, mid = _cut(line, d0)\n",
    "    mid, right = _cut(mid, d1 - d0)\n",
    "    return mid\n",
    "\n",
    "def crop_mesh(**kwargs):\n",
    "    mesh = kwargs['mesh']\n",
    "    data_path = kwargs['data_path']\n",
    "\n",
    "    with rasterio.open(data_path) as src:\n",
    "        r_crs = src.crs\n",
    "        nodata = src.nodata\n",
    "\n",
    "    cl_m = gpd.GeoSeries([mesh.centerline], crs='EPSG:4326').to_crs(r_crs).iloc[0]\n",
    "\n",
    "    target_samples = 400\n",
    "    step = max(cl_m.length / target_samples, 25.0)\n",
    "    dists = np.arange(0.0, cl_m.length + step, step, dtype=float)\n",
    "    pts = [cl_m.interpolate(float(d)) for d in dists]\n",
    "\n",
    "    with rasterio.open(data_path) as src:\n",
    "        vals = np.array([v[0] for v in src.sample([(p.x, p.y) for p in pts])])\n",
    "\n",
    "    valid = ~np.isnan(vals) if nodata is None else (vals != nodata)\n",
    "    if not valid.any():\n",
    "        raise ValueError('No valid data found along centerline for the provided raster.')\n",
    "\n",
    "    first = int(np.argmax(valid))\n",
    "    last = int(len(valid) - 1 - np.argmax(valid[::-1]))\n",
    "\n",
    "    # If no cropping is needed, return unchanged mesh\n",
    "    if first == 0 and last == len(valid) - 1:\n",
    "        return mesh\n",
    "\n",
    "    d0, d1 = float(dists[first]), float(dists[last])\n",
    "    cl_m_cropped = _segment(cl_m, d0, d1)\n",
    "    cl_ll = gpd.GeoSeries([cl_m_cropped], crs=r_crs).to_crs('EPSG:4326').iloc[0]\n",
    "\n",
    "    geod = Geod(ellps='WGS84')\n",
    "    xs, ys = np.asarray(cl_ll.xy[0]), np.asarray(cl_ll.xy[1])\n",
    "    segs = [geod.inv(xs[i], ys[i], xs[i + 1], ys[i + 1])[2] for i in range(len(xs) - 1)]\n",
    "    new_len = float(np.sum(segs))\n",
    "\n",
    "    n_cells = len(mesh.X) - 1\n",
    "    base_mesh = firedrake.IntervalMesh(n_cells, new_len)\n",
    "    extruded = firedrake.ExtrudedMesh(base_mesh, layers=1)\n",
    "    X = base_mesh.coordinates.dat.data_ro.flatten()\n",
    "    surface_coords = np.column_stack((X, np.ones_like(X)))\n",
    "    basal_coords = np.column_stack((X, np.zeros_like(X)))\n",
    "\n",
    "    return type(mesh)(\n",
    "        mesh = extruded,\n",
    "        x = xs,\n",
    "        y = ys,\n",
    "        X = X,\n",
    "        basal_coords = basal_coords,\n",
    "        surface_coords = surface_coords,\n",
    "        centerline = cl_ll,\n",
    "        outline = mesh.outline,\n",
    "        length = new_len,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f441d-e412-4ce4-90f0-bf6ea83fd14a",
   "metadata": {},
   "source": [
    "## map_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e873-7a6e-4d6e-9616-f2de05be3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_mesh(**kwargs):\n",
    "    \"\"\"\n",
    "    Map data onto the provided *extruded* mesh.\n",
    "\n",
    "    Use one of:\n",
    "      - function=<Firedrake Function>: reproject an existing field, or\n",
    "      - data_path=<.tif or .csv>: sample along the centerline and interpolate.\n",
    "\n",
    "    Options:\n",
    "      mesh: IntervalMeshResult (extruded)\n",
    "      element: str (default 'CG')\n",
    "      dimension: int polynomial degree (default 1)\n",
    "      ice_free_value: constant to apply outside the source x-extent (if provided)\n",
    "      projection: CRS string for rasters (default 'EPSG:4326')\n",
    "      key_value, data_value, key_dataset: CSV helpers (as in SIA)\n",
    "      target_space: optional FunctionSpace to write into (overrides element/dimension)\n",
    "    \"\"\"\n",
    "    mesh = kwargs['mesh']\n",
    "    data_path = kwargs.get('data_path', None)\n",
    "    function = kwargs.get('function', None)\n",
    "    degree = int(kwargs.get('dimension', 1))\n",
    "    family = kwargs.get('element', 'CG')\n",
    "    key_value = kwargs.get('key_value', 'n/a')\n",
    "    data_value = kwargs.get('data_value', 'n/a')\n",
    "    key_dataset = kwargs.get('key_dataset', None)\n",
    "    projection = kwargs.get('projection', 'EPSG:4326')\n",
    "    ice_free_value = kwargs.get('ice_free_value', None)\n",
    "    target_space = kwargs.get('target_space', None)\n",
    "\n",
    "    # Base-line vertices (chainage in meters) and basal coords (x, zeta=0)\n",
    "    X = mesh.X\n",
    "    basal_coords = mesh.basal_coords\n",
    "\n",
    "    # Helper: land values on CG(1)Ã—R^0 and (optionally) project to target space/degree\n",
    "    def _finalize(values_on_vertices):\n",
    "        V1 = firedrake.FunctionSpace(mesh.mesh, 'CG', 1, vfamily='R', vdegree=0)\n",
    "        f1 = firedrake.Function(V1)\n",
    "        f1.dat.data[:] = values_on_vertices\n",
    "        if target_space is not None:\n",
    "            return firedrake.project(f1, target_space)\n",
    "        if degree != 1 or family != 'CG':\n",
    "            Vt = firedrake.FunctionSpace(mesh.mesh, family, degree, vfamily='R', vdegree=0)\n",
    "            return firedrake.project(f1, Vt)\n",
    "        return f1\n",
    "\n",
    "    # ====================== Branch A: function â†’ mesh (no clamping) ======================\n",
    "    if function is not None:\n",
    "        src_mesh = function.function_space().mesh()\n",
    "        gdim = src_mesh.geometric_dimension()\n",
    "\n",
    "        # Source horizontal extent\n",
    "        try:\n",
    "            x_src = src_mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "        except AttributeError:\n",
    "            x_src = src_mesh.coordinates.dat.data_ro.flatten()\n",
    "        x_min, x_max = float(np.min(x_src)), float(np.max(x_src))\n",
    "        tol = 1e-10 * max(1.0, x_max - x_min)\n",
    "\n",
    "        # Mask target points that are inside the source domain\n",
    "        inside = (X >= x_min - tol) & (X <= x_max + tol)\n",
    "\n",
    "        if ice_free_value is None and not np.all(inside):\n",
    "            raise ValueError(\n",
    "                \"map_to_mesh(function=...) targets extend beyond the source function's domain. \"\n",
    "                \"Remap the source to the new mesh first (extend_to_mesh), or pass ice_free_value=...\"\n",
    "            )\n",
    "\n",
    "        # Prepare output; fill with ice_free_value if provided, else zeros (won't be used outside)\n",
    "        vals = np.empty_like(X, dtype=float)\n",
    "        if ice_free_value is not None:\n",
    "            vals[:] = float(ice_free_value)\n",
    "\n",
    "        # Evaluate only the inside points on the source mesh\n",
    "        if np.any(inside):\n",
    "            if gdim == 1:\n",
    "                vals_inside = np.array(function.at(X[inside], tolerance=1e-10)).reshape(-1)\n",
    "            else:\n",
    "                eval_pts = basal_coords[inside].copy()\n",
    "                vals_inside = np.array(function.at(eval_pts, tolerance=1e-10)).reshape(-1)\n",
    "            vals[inside] = vals_inside\n",
    "\n",
    "        return _finalize(vals)\n",
    "\n",
    "    # ====================== Branch B: file â†’ mesh ======================\n",
    "    if data_path is None:\n",
    "        raise ValueError('data_path is required unless you pass function=...')\n",
    "\n",
    "    extension = Path(data_path).suffix.lower()\n",
    "\n",
    "    if extension == '.tif':\n",
    "        x_ll, y_ll = mesh.x, mesh.y\n",
    "\n",
    "        with rasterio.open(data_path) as src:\n",
    "            src_crs = src.crs\n",
    "            tgt_crs = CRS.from_string(projection)\n",
    "\n",
    "            if src_crs != tgt_crs:\n",
    "                transform, width, height = calculate_default_transform(\n",
    "                    src_crs, tgt_crs, src.width, src.height, *src.bounds\n",
    "                )\n",
    "                meta = src.meta.copy()\n",
    "                meta.update({'crs': tgt_crs, 'transform': transform, 'width': width, 'height': height})\n",
    "                with MemoryFile() as memfile:\n",
    "                    with memfile.open(**meta) as dst:\n",
    "                        for i in range(1, src.count + 1):\n",
    "                            reproject(\n",
    "                                source=rasterio.band(src, i), destination=rasterio.band(dst, i),\n",
    "                                src_transform=src.transform, src_crs=src_crs,\n",
    "                                dst_transform=transform, dst_crs=tgt_crs,\n",
    "                                resampling=Resampling.bilinear,\n",
    "                            )\n",
    "                    with memfile.open() as reproj:\n",
    "                        sampled = np.array(list(reproj.sample(zip(x_ll, y_ll)))).flatten()\n",
    "            else:\n",
    "                sampled = np.array(list(src.sample(zip(x_ll, y_ll)))).flatten()\n",
    "\n",
    "        geod = Geod(ellps='WGS84')\n",
    "        chainage = np.insert(np.cumsum([\n",
    "            geod.inv(x_ll[i], y_ll[i], x_ll[i+1], y_ll[i+1])[2] for i in range(len(x_ll) - 1)\n",
    "        ]), 0, 0)\n",
    "\n",
    "        vals = interp1d(chainage, sampled, bounds_error=False, fill_value='extrapolate')(X)\n",
    "        if ice_free_value is not None:\n",
    "            vals[X > chainage[-1] + 1e-12] = ice_free_value\n",
    "\n",
    "        return _finalize(vals)\n",
    "\n",
    "    elif extension == '.csv':\n",
    "        df = pd.read_csv(data_path)\n",
    "        if key_value not in df.columns or data_value not in df.columns:\n",
    "            raise ValueError(f'CSV must include {key_value!r} and {data_value!r} columns.')\n",
    "        if key_dataset is None:\n",
    "            raise ValueError('Must provide \"key_dataset\" (a Firedrake Function) when using CSV input.')\n",
    "\n",
    "        key_array = key_dataset.dat.data_ro\n",
    "        vals = interp1d(df[key_value], df[data_value], bounds_error=False, fill_value='extrapolate')(key_array)\n",
    "\n",
    "        # Mirror SIA behavior: place result in the key dataset's space\n",
    "        V_csv = firedrake.FunctionSpace(mesh.mesh, key_dataset.function_space().ufl_element())\n",
    "        out_csv = firedrake.Function(V_csv)\n",
    "        out_csv.dat.data[:] = vals\n",
    "        return out_csv\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported file extension: {extension}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164ef62-c530-43a7-92c1-138ace2af59d",
   "metadata": {},
   "source": [
    "# extend_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c65c34-85a3-4b71-8b84-323c2f0fba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_to_mesh(**kwargs):\n",
    "    \"\"\"\n",
    "    Map a Firedrake Function onto the (extruded) target mesh.\n",
    "\n",
    "    Args:\n",
    "      function: source Firedrake Function\n",
    "      mesh: IntervalMeshResult (target extruded mesh)\n",
    "      ice_free_value: optional constant for outside-domain fill\n",
    "      target_space: optional FunctionSpace to land in (defaults to same element on target mesh)\n",
    "\n",
    "    Returns:\n",
    "      Firedrake Function on the target mesh.\n",
    "    \"\"\"\n",
    "    f_src = kwargs['function']\n",
    "    mesh = kwargs['mesh']\n",
    "    ice_free_value = kwargs.get('ice_free_value', None)\n",
    "    target_space = kwargs.get('target_space', None)\n",
    "\n",
    "    # Pick a target space that lives on the TARGET mesh.\n",
    "    V_tgt = target_space or firedrake.FunctionSpace(\n",
    "        mesh.mesh, f_src.function_space().ufl_element()\n",
    "    )\n",
    "\n",
    "    # If the source is ALREADY on the target mesh and the same element, just copy.\n",
    "    if (f_src.function_space().mesh() is V_tgt.mesh()\n",
    "        and f_src.function_space().ufl_element() == V_tgt.ufl_element()):\n",
    "        return f_src.copy(deepcopy=True)\n",
    "\n",
    "    # Otherwise, actually map to the target mesh/space.\n",
    "    return map_to_mesh(\n",
    "        mesh=mesh,\n",
    "        function=f_src,\n",
    "        target_space=V_tgt,\n",
    "        ice_free_value=ice_free_value,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4e10b-2bed-4d20-aeb1-5bd3be773165",
   "metadata": {},
   "source": [
    "# smooth_extruded_function\n",
    "\n",
    "Important for icepack's HO model, which can be somewhat finicky with convergence, especially when there's a lot of jitter in certain fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbba162-6465-49f4-8549-8159958fd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_function(**kwargs):\n",
    "    \"\"\"\n",
    "    Depth-average a scalar field on the extruded mesh, smooth along X with a 1-D Gaussian,\n",
    "    then lift back into the original function space on the same mesh.\n",
    "\n",
    "    Args:\n",
    "      function: Firedrake Function (on extruded mesh)\n",
    "      mesh: IntervalMeshResult (extruded)\n",
    "      sigma: optional Gaussian sigma in grid points (overrides window)\n",
    "      window: optional window width in meters (approx 2*sigma*dx)\n",
    "\n",
    "    Returns:\n",
    "      Firedrake Function in the same space as `function`.\n",
    "    \"\"\"\n",
    "    f = kwargs['function']\n",
    "    mesh = kwargs['mesh']\n",
    "    sigma = kwargs.get('sigma', None)\n",
    "    window_m = kwargs.get('window', None)\n",
    "\n",
    "    # 1) depth-average to 1-D\n",
    "    f_flat = icepack.depth_average(f)\n",
    "    data = f_flat.dat.data_ro.copy()\n",
    "\n",
    "    # 2) choose sigma (in grid points) from requested window (meters)\n",
    "    X = mesh.X\n",
    "    dx = float(np.mean(np.diff(X))) if len(X) > 1 else 1.0\n",
    "    if sigma is None:\n",
    "        if window_m is None:\n",
    "            raise ValueError(\"Provide either 'sigma' (grid pts) or 'window' (meters).\")\n",
    "        sigma = (window_m / dx) / 2.0  # ~ 2Ïƒ â‰ˆ FWHM heuristic\n",
    "\n",
    "    # 3) smooth in 1-D along chainage\n",
    "    data_s = scipy.ndimage.gaussian_filter1d(data, sigma=float(sigma))\n",
    "\n",
    "    f_flat_s = f_flat.copy(deepcopy=True)\n",
    "    f_flat_s.dat.data[:] = data_s\n",
    "\n",
    "    # 4) lift back to the original space on the same mesh\n",
    "    return map_to_mesh(mesh=mesh, function=f_flat_s, target_space=f.function_space(), ice_free_value=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccece1a2-0a56-44cd-bb8e-778b84c774d0",
   "metadata": {},
   "source": [
    "## solve_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f6e5d-0c77-4fbb-b051-03682a77b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InversionResult:\n",
    "    bed: firedrake.Function\n",
    "    misfits: list\n",
    "    bed_evolution: list\n",
    "    surface_evolution: list\n",
    "    thickness_evolution: list\n",
    "    velocity_evolution: list\n",
    "    s_ref: firedrake.Function\n",
    "\n",
    "\n",
    "def solve_bed(**kwargs):\n",
    "    # Inputs\n",
    "    mesh = kwargs['mesh']\n",
    "    s_init = kwargs['surface']\n",
    "    s_ref = kwargs.get('surface_2', s_init)       \n",
    "    H_guess = kwargs['thickness_guess']\n",
    "    u_guess = kwargs['velocity']\n",
    "    a = kwargs['accumulation']\n",
    "    A = kwargs['fluidity']\n",
    "    K = kwargs['K']\n",
    "    num_iterations = kwargs['num_iterations']\n",
    "    model = kwargs['model']\n",
    "    solver = kwargs['solver']\n",
    "    friction = kwargs['friction']\n",
    "\n",
    "    try: num_years = s_ref.year - s_init.year #extract the time diff from the DEMs, if applicable\n",
    "    except: num_years = kwargs['model_time'] #otherwise, need to choose how long to model for \n",
    "\n",
    "    try: Î”t = round(list(a)[1] - list(a)[0], 10) #extract Î”t from the SMB list, if applicable\n",
    "    except: Î”t = kwargs['timestep'] #otherwise, it needs to be specified\n",
    "\n",
    "    # Function space and coordinates\n",
    "    Q = s_init.function_space()\n",
    "    base_coords = mesh.mesh._base_mesh.coordinates.dat.data_ro.flatten()\n",
    "\n",
    "    # Initial bed guess\n",
    "    bed_guess = firedrake.Function(Q).project(s_init - H_guess)\n",
    "\n",
    "    # Initialize storage\n",
    "    misfits = []\n",
    "    bed_evolution = [bed_guess.dat.data_ro.copy()]\n",
    "    surface_evolution = []\n",
    "    velocity_evolution = []\n",
    "    thickness_evolution = []\n",
    "\n",
    "    num_timesteps = int(num_years/Î”t)\n",
    "\n",
    "    bed_correction = firedrake.Function(Q)\n",
    "    surface_misfit = firedrake.Function(Q)\n",
    "\n",
    "    for iteration in trange(num_iterations):\n",
    "        bed_mod = bed_guess.copy(deepcopy = True)\n",
    "        H_mod = firedrake.Function(Q).project(s_init - bed_mod)\n",
    "        H_0 = H_mod.copy(deepcopy = True)\n",
    "        u_mod = u_guess.copy(deepcopy = True)\n",
    "        s_mod = s_init.copy(deepcopy = True)\n",
    "\n",
    "        for step in range(num_timesteps):\n",
    "\n",
    "            try: accumulation = a[s_init.year + step*Î”t] #if SMB is a dictionary with date keys\n",
    "            except: accumulation = a #otherwise\n",
    "\n",
    "            try:\n",
    "                u_mod = solver.diagnostic_solve(\n",
    "                    velocity = u_mod,\n",
    "                    thickness = H_mod,\n",
    "                    surface = s_mod,\n",
    "                    fluidity = A,\n",
    "                    friction = friction\n",
    "                )\n",
    "                \n",
    "                H_mod = solver.prognostic_solve(\n",
    "                    Î”t,\n",
    "                    thickness = H_mod,\n",
    "                    velocity = u_mod,\n",
    "                    thickness_inflow = H_0,\n",
    "                    accumulation = accumulation,\n",
    "                )\n",
    "                s_mod.project(icepack.compute_surface(bed = bed_mod, thickness = H_mod))\n",
    "\n",
    "            except:\n",
    "                print(f'Bed solver failed on step {step + 1} of iteration {iteration + 1}')\n",
    "\n",
    "                return InversionResult(\n",
    "                    bed = bed_guess,\n",
    "                    misfits = misfits,\n",
    "                    bed_evolution = bed_evolution,\n",
    "                    surface_evolution = surface_evolution,\n",
    "                    velocity_evolution = velocity_evolution,\n",
    "                    thickness_evolution = thickness_evolution,\n",
    "                    s_ref = s_ref\n",
    "                )\n",
    "\n",
    "        surface_misfit.project(s_mod - s_ref)\n",
    "        bed_correction.project(-K * surface_misfit)\n",
    "        bed_guess.project(bed_mod + bed_correction)\n",
    "\n",
    "        # Store evolution values\n",
    "        misfits.append(float(firedrake.assemble(surface_misfit*firedrake.dx)/mesh.length))\n",
    "        # misfits.append(np.linalg.norm(surface_misfit.dat.data_ro))\n",
    "        bed_evolution.append(bed_guess.dat.data_ro.copy())\n",
    "        surface_evolution.append(s_mod.dat.data_ro.copy())\n",
    "        thickness_evolution.append(H_mod.dat.data_ro.copy())\n",
    "        velocity_lifted = map_to_mesh(function = icepack.depth_average(u_mod), mesh = mesh)\n",
    "        velocity_evolution.append(velocity_lifted.dat.data_ro.copy())\n",
    "\n",
    "    return InversionResult(\n",
    "        bed = bed_guess,\n",
    "        misfits = misfits,\n",
    "        bed_evolution = bed_evolution,\n",
    "        surface_evolution = surface_evolution,\n",
    "        velocity_evolution = velocity_evolution,\n",
    "        thickness_evolution = thickness_evolution,\n",
    "        s_ref = s_ref\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63f4cd-59e7-437c-b94e-2ac269cea457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script centerflow_extruded.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev2025)",
   "language": "python",
   "name": "dev2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
